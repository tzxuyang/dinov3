{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d202396d-3549-4f1d-b0b2-c8e0a5f30493",
   "metadata": {},
   "source": [
    "* https://github.com/little51/dinov3-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c38ff61-acc5-460a-8852-2a5978f9de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm==1.0.20 -i https://pypi.mirrors.ustc.edu.cn/simple\n",
    "# !pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2abf809-131f-4b46-adb4-e91eb41590a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn  ## torch neural network\n",
    "import timm  ## timm is a library for vision model \n",
    "from torchvision import datasets  # lib to load torchvision model\n",
    "import torch  # torch\n",
    "\n",
    "REPO_DIR = \"/home/yang/MyRepos/dinov3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3367f11-8141-436c-8708-570e875830d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "REPO_DIR = \"/home/yang/MyRepos/dinov3\"\n",
    "BACKBONE_DIR = \"/home/yang/MyRepos/meta_dino_models/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth\"\n",
    "# BACKBONE_DIR = \"/home/yang/MyRepos/meta_dino_models/dinov3_vit7b16_pretrain_lvd1689m-a955f4ea.pth\"\n",
    "DEPTHER_DIR = \"/home/yang/MyRepos/meta_dino_models/dinov3_vit7b16_imagenet1k_linear_head-90d8ed92.pth\"\n",
    "\n",
    "dinov3_vitl16 = torch.hub.load(REPO_DIR, 'dinov3_vitl16', source='local', weights=BACKBONE_DIR)\n",
    "# dinov3_vit7b16_lc = torch.hub.load(REPO_DIR, 'dinov3_vith16plus', source=\"local\", weights=DEPTHER_DIR, backbone_weights=BACKBONE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05beec-cf34-4f48-8da1-4c9f82c7dc32",
   "metadata": {},
   "source": [
    "# Download BackBone model\n",
    "* Note that it uses num_classes=0 to disable classification head of the backbone\n",
    "* It freezes all the parameters to prevent back-propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfc88de-c3d6-4e2f-992e-84a345514a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aimv2_1b_patch14_224', 'aimv2_1b_patch14_336', 'aimv2_1b_patch14_448', 'aimv2_3b_patch14_224', 'aimv2_3b_patch14_336', 'aimv2_3b_patch14_448', 'aimv2_huge_patch14_224', 'aimv2_huge_patch14_336', 'aimv2_huge_patch14_448', 'aimv2_large_patch14_224', 'aimv2_large_patch14_336', 'aimv2_large_patch14_448', 'bat_resnext26ts', 'beit3_base_patch16_224', 'beit3_giant_patch14_224', 'beit3_giant_patch14_336', 'beit3_large_patch16_224', 'beit_base_patch16_224', 'beit_base_patch16_384', 'beit_large_patch16_224', 'beit_large_patch16_384', 'beit_large_patch16_512', 'beitv2_base_patch16_224', 'beitv2_large_patch16_224', 'botnet26t_256', 'botnet50ts_256', 'caformer_b36', 'caformer_m36', 'caformer_s18', 'caformer_s36', 'cait_m36_384', 'cait_m48_448', 'cait_s24_224', 'cait_s24_384', 'cait_s36_384', 'cait_xs24_384', 'cait_xxs24_224', 'cait_xxs24_384', 'cait_xxs36_224', 'cait_xxs36_384', 'coat_lite_medium', 'coat_lite_medium_384', 'coat_lite_mini', 'coat_lite_small', 'coat_lite_tiny', 'coat_mini', 'coat_small', 'coat_tiny', 'coatnet_0_224', 'coatnet_0_rw_224', 'coatnet_1_224', 'coatnet_1_rw_224', 'coatnet_2_224', 'coatnet_2_rw_224', 'coatnet_3_224', 'coatnet_3_rw_224', 'coatnet_4_224', 'coatnet_5_224', 'coatnet_bn_0_rw_224', 'coatnet_nano_cc_224', 'coatnet_nano_rw_224', 'coatnet_pico_rw_224', 'coatnet_rmlp_0_rw_224', 'coatnet_rmlp_1_rw2_224', 'coatnet_rmlp_1_rw_224', 'coatnet_rmlp_2_rw_224', 'coatnet_rmlp_2_rw_384', 'coatnet_rmlp_3_rw_224', 'coatnet_rmlp_nano_rw_224', 'coatnext_nano_rw_224', 'convformer_b36', 'convformer_m36', 'convformer_s18', 'convformer_s36', 'convit_base', 'convit_small', 'convit_tiny', 'convmixer_768_32', 'convmixer_1024_20_ks9_p14', 'convmixer_1536_20', 'convnext_atto', 'convnext_atto_ols', 'convnext_atto_rms', 'convnext_base', 'convnext_femto', 'convnext_femto_ols', 'convnext_large', 'convnext_large_mlp', 'convnext_nano', 'convnext_nano_ols', 'convnext_pico', 'convnext_pico_ols', 'convnext_small', 'convnext_tiny', 'convnext_tiny_hnf', 'convnext_xlarge', 'convnext_xxlarge', 'convnext_zepto_rms', 'convnext_zepto_rms_ols', 'convnextv2_atto', 'convnextv2_base', 'convnextv2_femto', 'convnextv2_huge', 'convnextv2_large', 'convnextv2_nano', 'convnextv2_pico', 'convnextv2_small', 'convnextv2_tiny', 'crossvit_9_240', 'crossvit_9_dagger_240', 'crossvit_15_240', 'crossvit_15_dagger_240', 'crossvit_15_dagger_408', 'crossvit_18_240', 'crossvit_18_dagger_240', 'crossvit_18_dagger_408', 'crossvit_base_240', 'crossvit_small_240', 'crossvit_tiny_240', 'cs3darknet_focus_l', 'cs3darknet_focus_m', 'cs3darknet_focus_s', 'cs3darknet_focus_x', 'cs3darknet_l', 'cs3darknet_m', 'cs3darknet_s', 'cs3darknet_x', 'cs3edgenet_x', 'cs3se_edgenet_x', 'cs3sedarknet_l', 'cs3sedarknet_x', 'cs3sedarknet_xdw', 'cspdarknet53', 'cspresnet50', 'cspresnet50d', 'cspresnet50w', 'cspresnext50', 'darknet17', 'darknet21', 'darknet53', 'darknetaa53', 'davit_base', 'davit_base_fl', 'davit_giant', 'davit_huge', 'davit_huge_fl', 'davit_large', 'davit_small', 'davit_tiny', 'deit3_base_patch16_224', 'deit3_base_patch16_384', 'deit3_huge_patch14_224', 'deit3_large_patch16_224', 'deit3_large_patch16_384', 'deit3_medium_patch16_224', 'deit3_small_patch16_224', 'deit3_small_patch16_384', 'deit_base_distilled_patch16_224', 'deit_base_distilled_patch16_384', 'deit_base_patch16_224', 'deit_base_patch16_384', 'deit_small_distilled_patch16_224', 'deit_small_patch16_224', 'deit_tiny_distilled_patch16_224', 'deit_tiny_patch16_224', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'densenet264d', 'densenetblur121d', 'dla34', 'dla46_c', 'dla46x_c', 'dla60', 'dla60_res2net', 'dla60_res2next', 'dla60x', 'dla60x_c', 'dla102', 'dla102x', 'dla102x2', 'dla169', 'dm_nfnet_f0', 'dm_nfnet_f1', 'dm_nfnet_f2', 'dm_nfnet_f3', 'dm_nfnet_f4', 'dm_nfnet_f5', 'dm_nfnet_f6', 'dpn48b', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'eca_botnext26ts_256', 'eca_halonext26ts', 'eca_nfnet_l0', 'eca_nfnet_l1', 'eca_nfnet_l2', 'eca_nfnet_l3', 'eca_resnet33ts', 'eca_resnext26ts', 'eca_vovnet39b', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50d_pruned', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet101d_pruned', 'ecaresnet200d', 'ecaresnet269d', 'ecaresnetlight', 'ecaresnext26t_32x4d', 'ecaresnext50t_32x4d', 'edgenext_base', 'edgenext_small', 'edgenext_small_rw', 'edgenext_x_small', 'edgenext_xx_small', 'efficientformer_l1', 'efficientformer_l3', 'efficientformer_l7', 'efficientformerv2_l', 'efficientformerv2_s0', 'efficientformerv2_s1', 'efficientformerv2_s2', 'efficientnet_b0', 'efficientnet_b0_g8_gn', 'efficientnet_b0_g16_evos', 'efficientnet_b0_gn', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b3', 'efficientnet_b3_g8_gn', 'efficientnet_b3_gn', 'efficientnet_b3_pruned', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_b8', 'efficientnet_blur_b0', 'efficientnet_cc_b0_4e', 'efficientnet_cc_b0_8e', 'efficientnet_cc_b1_8e', 'efficientnet_el', 'efficientnet_el_pruned', 'efficientnet_em', 'efficientnet_es', 'efficientnet_es_pruned', 'efficientnet_h_b5', 'efficientnet_l2', 'efficientnet_lite0', 'efficientnet_lite1', 'efficientnet_lite2', 'efficientnet_lite3', 'efficientnet_lite4', 'efficientnet_x_b3', 'efficientnet_x_b5', 'efficientnetv2_l', 'efficientnetv2_m', 'efficientnetv2_rw_m', 'efficientnetv2_rw_s', 'efficientnetv2_rw_t', 'efficientnetv2_s', 'efficientnetv2_xl', 'efficientvit_b0', 'efficientvit_b1', 'efficientvit_b2', 'efficientvit_b3', 'efficientvit_l1', 'efficientvit_l2', 'efficientvit_l3', 'efficientvit_m0', 'efficientvit_m1', 'efficientvit_m2', 'efficientvit_m3', 'efficientvit_m4', 'efficientvit_m5', 'ese_vovnet19b_dw', 'ese_vovnet19b_slim', 'ese_vovnet19b_slim_dw', 'ese_vovnet39b', 'ese_vovnet39b_evos', 'ese_vovnet57b', 'ese_vovnet99b', 'eva02_base_patch14_224', 'eva02_base_patch14_448', 'eva02_base_patch16_clip_224', 'eva02_enormous_patch14_clip_224', 'eva02_large_patch14_224', 'eva02_large_patch14_448', 'eva02_large_patch14_clip_224', 'eva02_large_patch14_clip_336', 'eva02_small_patch14_224', 'eva02_small_patch14_336', 'eva02_tiny_patch14_224', 'eva02_tiny_patch14_336', 'eva_giant_patch14_224', 'eva_giant_patch14_336', 'eva_giant_patch14_560', 'eva_giant_patch14_clip_224', 'eva_large_patch14_196', 'eva_large_patch14_336', 'fasternet_l', 'fasternet_m', 'fasternet_s', 'fasternet_t0', 'fasternet_t1', 'fasternet_t2', 'fastvit_ma36', 'fastvit_mci0', 'fastvit_mci1', 'fastvit_mci2', 'fastvit_mci3', 'fastvit_mci4', 'fastvit_s12', 'fastvit_sa12', 'fastvit_sa24', 'fastvit_sa36', 'fastvit_t8', 'fastvit_t12', 'fbnetc_100', 'fbnetv3_b', 'fbnetv3_d', 'fbnetv3_g', 'flexivit_base', 'flexivit_large', 'flexivit_small', 'focalnet_base_lrf', 'focalnet_base_srf', 'focalnet_huge_fl3', 'focalnet_huge_fl4', 'focalnet_large_fl3', 'focalnet_large_fl4', 'focalnet_small_lrf', 'focalnet_small_srf', 'focalnet_tiny_lrf', 'focalnet_tiny_srf', 'focalnet_xlarge_fl3', 'focalnet_xlarge_fl4', 'gc_efficientnetv2_rw_t', 'gcresnet33ts', 'gcresnet50t', 'gcresnext26ts', 'gcresnext50ts', 'gcvit_base', 'gcvit_small', 'gcvit_tiny', 'gcvit_xtiny', 'gcvit_xxtiny', 'gernet_l', 'gernet_m', 'gernet_s', 'ghostnet_050', 'ghostnet_100', 'ghostnet_130', 'ghostnetv2_100', 'ghostnetv2_130', 'ghostnetv2_160', 'ghostnetv3_050', 'ghostnetv3_100', 'ghostnetv3_130', 'ghostnetv3_160', 'gmixer_12_224', 'gmixer_24_224', 'gmlp_b16_224', 'gmlp_s16_224', 'gmlp_ti16_224', 'halo2botnet50ts_256', 'halonet26t', 'halonet50ts', 'halonet_h1', 'haloregnetz_b', 'hardcorenas_a', 'hardcorenas_b', 'hardcorenas_c', 'hardcorenas_d', 'hardcorenas_e', 'hardcorenas_f', 'hgnet_base', 'hgnet_small', 'hgnet_tiny', 'hgnetv2_b0', 'hgnetv2_b1', 'hgnetv2_b2', 'hgnetv2_b3', 'hgnetv2_b4', 'hgnetv2_b5', 'hgnetv2_b6', 'hiera_base_224', 'hiera_base_abswin_256', 'hiera_base_plus_224', 'hiera_huge_224', 'hiera_large_224', 'hiera_small_224', 'hiera_small_abswin_256', 'hiera_tiny_224', 'hieradet_small', 'hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w18_ssld', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w48_ssld', 'hrnet_w64', 'inception_next_atto', 'inception_next_base', 'inception_next_small', 'inception_next_tiny', 'inception_resnet_v2', 'inception_v3', 'inception_v4', 'lambda_resnet26rpt_256', 'lambda_resnet26t', 'lambda_resnet50ts', 'lamhalobotnet50ts_256', 'lcnet_035', 'lcnet_050', 'lcnet_075', 'lcnet_100', 'lcnet_150', 'legacy_senet154', 'legacy_seresnet18', 'legacy_seresnet34', 'legacy_seresnet50', 'legacy_seresnet101', 'legacy_seresnet152', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'legacy_xception', 'levit_128', 'levit_128s', 'levit_192', 'levit_256', 'levit_256d', 'levit_384', 'levit_384_s8', 'levit_512', 'levit_512_s8', 'levit_512d', 'levit_conv_128', 'levit_conv_128s', 'levit_conv_192', 'levit_conv_256', 'levit_conv_256d', 'levit_conv_384', 'levit_conv_384_s8', 'levit_conv_512', 'levit_conv_512_s8', 'levit_conv_512d', 'mambaout_base', 'mambaout_base_plus_rw', 'mambaout_base_short_rw', 'mambaout_base_tall_rw', 'mambaout_base_wide_rw', 'mambaout_femto', 'mambaout_kobe', 'mambaout_small', 'mambaout_small_rw', 'mambaout_tiny', 'maxvit_base_tf_224', 'maxvit_base_tf_384', 'maxvit_base_tf_512', 'maxvit_large_tf_224', 'maxvit_large_tf_384', 'maxvit_large_tf_512', 'maxvit_nano_rw_256', 'maxvit_pico_rw_256', 'maxvit_rmlp_base_rw_224', 'maxvit_rmlp_base_rw_384', 'maxvit_rmlp_nano_rw_256', 'maxvit_rmlp_pico_rw_256', 'maxvit_rmlp_small_rw_224', 'maxvit_rmlp_small_rw_256', 'maxvit_rmlp_tiny_rw_256', 'maxvit_small_tf_224', 'maxvit_small_tf_384', 'maxvit_small_tf_512', 'maxvit_tiny_pm_256', 'maxvit_tiny_rw_224', 'maxvit_tiny_rw_256', 'maxvit_tiny_tf_224', 'maxvit_tiny_tf_384', 'maxvit_tiny_tf_512', 'maxvit_xlarge_tf_224', 'maxvit_xlarge_tf_384', 'maxvit_xlarge_tf_512', 'maxxvit_rmlp_nano_rw_256', 'maxxvit_rmlp_small_rw_256', 'maxxvit_rmlp_tiny_rw_256', 'maxxvitv2_nano_rw_256', 'maxxvitv2_rmlp_base_rw_224', 'maxxvitv2_rmlp_base_rw_384', 'maxxvitv2_rmlp_large_rw_224', 'mixer_b16_224', 'mixer_b32_224', 'mixer_l16_224', 'mixer_l32_224', 'mixer_s16_224', 'mixer_s32_224', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mixnet_xxl', 'mnasnet_050', 'mnasnet_075', 'mnasnet_100', 'mnasnet_140', 'mnasnet_small', 'mobilenet_edgetpu_100', 'mobilenet_edgetpu_v2_l', 'mobilenet_edgetpu_v2_m', 'mobilenet_edgetpu_v2_s', 'mobilenet_edgetpu_v2_xs', 'mobilenetv1_100', 'mobilenetv1_100h', 'mobilenetv1_125', 'mobilenetv2_035', 'mobilenetv2_050', 'mobilenetv2_075', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_075', 'mobilenetv3_large_100', 'mobilenetv3_large_150d', 'mobilenetv3_rw', 'mobilenetv3_small_050', 'mobilenetv3_small_075', 'mobilenetv3_small_100', 'mobilenetv4_conv_aa_large', 'mobilenetv4_conv_aa_medium', 'mobilenetv4_conv_blur_medium', 'mobilenetv4_conv_large', 'mobilenetv4_conv_medium', 'mobilenetv4_conv_small', 'mobilenetv4_conv_small_035', 'mobilenetv4_conv_small_050', 'mobilenetv4_hybrid_large', 'mobilenetv4_hybrid_large_075', 'mobilenetv4_hybrid_medium', 'mobilenetv4_hybrid_medium_075', 'mobilenetv5_300m', 'mobilenetv5_300m_enc', 'mobilenetv5_base', 'mobileone_s0', 'mobileone_s1', 'mobileone_s2', 'mobileone_s3', 'mobileone_s4', 'mobilevit_s', 'mobilevit_xs', 'mobilevit_xxs', 'mobilevitv2_050', 'mobilevitv2_075', 'mobilevitv2_100', 'mobilevitv2_125', 'mobilevitv2_150', 'mobilevitv2_175', 'mobilevitv2_200', 'mvitv2_base', 'mvitv2_base_cls', 'mvitv2_huge_cls', 'mvitv2_large', 'mvitv2_large_cls', 'mvitv2_small', 'mvitv2_small_cls', 'mvitv2_tiny', 'naflexvit_base_patch16_gap', 'naflexvit_base_patch16_map', 'naflexvit_base_patch16_par_gap', 'naflexvit_base_patch16_parfac_gap', 'naflexvit_base_patch16_siglip', 'naflexvit_so150m2_patch16_reg1_gap', 'naflexvit_so150m2_patch16_reg1_map', 'naflexvit_so400m_patch16_siglip', 'nasnetalarge', 'nest_base', 'nest_base_jx', 'nest_small', 'nest_small_jx', 'nest_tiny', 'nest_tiny_jx', 'nextvit_base', 'nextvit_large', 'nextvit_small', 'nf_ecaresnet26', 'nf_ecaresnet50', 'nf_ecaresnet101', 'nf_regnet_b0', 'nf_regnet_b1', 'nf_regnet_b2', 'nf_regnet_b3', 'nf_regnet_b4', 'nf_regnet_b5', 'nf_resnet26', 'nf_resnet50', 'nf_resnet101', 'nf_seresnet26', 'nf_seresnet50', 'nf_seresnet101', 'nfnet_f0', 'nfnet_f1', 'nfnet_f2', 'nfnet_f3', 'nfnet_f4', 'nfnet_f5', 'nfnet_f6', 'nfnet_f7', 'nfnet_l0', 'pit_b_224', 'pit_b_distilled_224', 'pit_s_224', 'pit_s_distilled_224', 'pit_ti_224', 'pit_ti_distilled_224', 'pit_xs_224', 'pit_xs_distilled_224', 'pnasnet5large', 'poolformer_m36', 'poolformer_m48', 'poolformer_s12', 'poolformer_s24', 'poolformer_s36', 'poolformerv2_m36', 'poolformerv2_m48', 'poolformerv2_s12', 'poolformerv2_s24', 'poolformerv2_s36', 'pvt_v2_b0', 'pvt_v2_b1', 'pvt_v2_b2', 'pvt_v2_b2_li', 'pvt_v2_b3', 'pvt_v2_b4', 'pvt_v2_b5', 'rdnet_base', 'rdnet_large', 'rdnet_small', 'rdnet_tiny', 'regnetv_040', 'regnetv_064', 'regnetx_002', 'regnetx_004', 'regnetx_004_tv', 'regnetx_006', 'regnetx_008', 'regnetx_016', 'regnetx_032', 'regnetx_040', 'regnetx_064', 'regnetx_080', 'regnetx_120', 'regnetx_160', 'regnetx_320', 'regnety_002', 'regnety_004', 'regnety_006', 'regnety_008', 'regnety_008_tv', 'regnety_016', 'regnety_032', 'regnety_040', 'regnety_040_sgn', 'regnety_064', 'regnety_080', 'regnety_080_tv', 'regnety_120', 'regnety_160', 'regnety_320', 'regnety_640', 'regnety_1280', 'regnety_2560', 'regnetz_005', 'regnetz_040', 'regnetz_040_h', 'regnetz_b16', 'regnetz_b16_evos', 'regnetz_c16', 'regnetz_c16_evos', 'regnetz_d8', 'regnetz_d8_evos', 'regnetz_d32', 'regnetz_e8', 'repghostnet_050', 'repghostnet_058', 'repghostnet_080', 'repghostnet_100', 'repghostnet_111', 'repghostnet_130', 'repghostnet_150', 'repghostnet_200', 'repvgg_a0', 'repvgg_a1', 'repvgg_a2', 'repvgg_b0', 'repvgg_b1', 'repvgg_b1g4', 'repvgg_b2', 'repvgg_b2g4', 'repvgg_b3', 'repvgg_b3g4', 'repvgg_d2se', 'repvit_m0_9', 'repvit_m1', 'repvit_m1_0', 'repvit_m1_1', 'repvit_m1_5', 'repvit_m2', 'repvit_m2_3', 'repvit_m3', 'res2net50_14w_8s', 'res2net50_26w_4s', 'res2net50_26w_6s', 'res2net50_26w_8s', 'res2net50_48w_2s', 'res2net50d', 'res2net101_26w_4s', 'res2net101d', 'res2next50', 'resmlp_12_224', 'resmlp_24_224', 'resmlp_36_224', 'resmlp_big_24_224', 'resnest14d', 'resnest26d', 'resnest50d', 'resnest50d_1s4x24d', 'resnest50d_4s2x40d', 'resnest101e', 'resnest200e', 'resnest269e', 'resnet10t', 'resnet14t', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet26t', 'resnet32ts', 'resnet33ts', 'resnet34', 'resnet34d', 'resnet50', 'resnet50_clip', 'resnet50_clip_gap', 'resnet50_gn', 'resnet50_mlp', 'resnet50c', 'resnet50d', 'resnet50s', 'resnet50t', 'resnet50x4_clip', 'resnet50x4_clip_gap', 'resnet50x16_clip', 'resnet50x16_clip_gap', 'resnet50x64_clip', 'resnet50x64_clip_gap', 'resnet51q', 'resnet61q', 'resnet101', 'resnet101_clip', 'resnet101_clip_gap', 'resnet101c', 'resnet101d', 'resnet101s', 'resnet152', 'resnet152c', 'resnet152d', 'resnet152s', 'resnet200', 'resnet200d', 'resnetaa34d', 'resnetaa50', 'resnetaa50d', 'resnetaa101d', 'resnetblur18', 'resnetblur50', 'resnetblur50d', 'resnetblur101d', 'resnetrs50', 'resnetrs101', 'resnetrs152', 'resnetrs200', 'resnetrs270', 'resnetrs350', 'resnetrs420', 'resnetv2_18', 'resnetv2_18d', 'resnetv2_34', 'resnetv2_34d', 'resnetv2_50', 'resnetv2_50d', 'resnetv2_50d_evos', 'resnetv2_50d_frn', 'resnetv2_50d_gn', 'resnetv2_50t', 'resnetv2_50x1_bit', 'resnetv2_50x3_bit', 'resnetv2_101', 'resnetv2_101d', 'resnetv2_101x1_bit', 'resnetv2_101x3_bit', 'resnetv2_152', 'resnetv2_152d', 'resnetv2_152x2_bit', 'resnetv2_152x4_bit', 'resnext26ts', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x4d', 'resnext101_32x8d', 'resnext101_32x16d', 'resnext101_32x32d', 'resnext101_64x4d', 'rexnet_100', 'rexnet_130', 'rexnet_150', 'rexnet_200', 'rexnet_300', 'rexnetr_100', 'rexnetr_130', 'rexnetr_150', 'rexnetr_200', 'rexnetr_300', 'sam2_hiera_base_plus', 'sam2_hiera_large', 'sam2_hiera_small', 'sam2_hiera_tiny', 'samvit_base_patch16', 'samvit_base_patch16_224', 'samvit_huge_patch16', 'samvit_large_patch16', 'sebotnet33ts_256', 'sedarknet21', 'sehalonet33ts', 'selecsls42', 'selecsls42b', 'selecsls60', 'selecsls60b', 'selecsls84', 'semnasnet_050', 'semnasnet_075', 'semnasnet_100', 'semnasnet_140', 'senet154', 'sequencer2d_l', 'sequencer2d_m', 'sequencer2d_s', 'seresnet18', 'seresnet33ts', 'seresnet34', 'seresnet50', 'seresnet50t', 'seresnet101', 'seresnet152', 'seresnet152d', 'seresnet200d', 'seresnet269d', 'seresnetaa50d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext26ts', 'seresnext50_32x4d', 'seresnext101_32x4d', 'seresnext101_32x8d', 'seresnext101_64x4d', 'seresnext101d_32x8d', 'seresnextaa101d_32x8d', 'seresnextaa201d_32x8d', 'shvit_s1', 'shvit_s2', 'shvit_s3', 'shvit_s4', 'skresnet18', 'skresnet34', 'skresnet50', 'skresnet50d', 'skresnext50_32x4d', 'spnasnet_100', 'starnet_s1', 'starnet_s2', 'starnet_s3', 'starnet_s4', 'starnet_s050', 'starnet_s100', 'starnet_s150', 'swiftformer_l1', 'swiftformer_l3', 'swiftformer_s', 'swiftformer_xs', 'swin_base_patch4_window7_224', 'swin_base_patch4_window12_384', 'swin_large_patch4_window7_224', 'swin_large_patch4_window12_384', 'swin_s3_base_224', 'swin_s3_small_224', 'swin_s3_tiny_224', 'swin_small_patch4_window7_224', 'swin_tiny_patch4_window7_224', 'swinv2_base_window8_256', 'swinv2_base_window12_192', 'swinv2_base_window12to16_192to256', 'swinv2_base_window12to24_192to384', 'swinv2_base_window16_256', 'swinv2_cr_base_224', 'swinv2_cr_base_384', 'swinv2_cr_base_ns_224', 'swinv2_cr_giant_224', 'swinv2_cr_giant_384', 'swinv2_cr_huge_224', 'swinv2_cr_huge_384', 'swinv2_cr_large_224', 'swinv2_cr_large_384', 'swinv2_cr_small_224', 'swinv2_cr_small_384', 'swinv2_cr_small_ns_224', 'swinv2_cr_small_ns_256', 'swinv2_cr_tiny_224', 'swinv2_cr_tiny_384', 'swinv2_cr_tiny_ns_224', 'swinv2_large_window12_192', 'swinv2_large_window12to16_192to256', 'swinv2_large_window12to24_192to384', 'swinv2_small_window8_256', 'swinv2_small_window16_256', 'swinv2_tiny_window8_256', 'swinv2_tiny_window16_256', 'test_byobnet', 'test_convnext', 'test_convnext2', 'test_convnext3', 'test_efficientnet', 'test_efficientnet_evos', 'test_efficientnet_gn', 'test_efficientnet_ln', 'test_mambaout', 'test_nfnet', 'test_resnet', 'test_vit', 'test_vit2', 'test_vit3', 'test_vit4', 'tf_efficientnet_b0', 'tf_efficientnet_b1', 'tf_efficientnet_b2', 'tf_efficientnet_b3', 'tf_efficientnet_b4', 'tf_efficientnet_b5', 'tf_efficientnet_b6', 'tf_efficientnet_b7', 'tf_efficientnet_b8', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_efficientnetv2_b0', 'tf_efficientnetv2_b1', 'tf_efficientnetv2_b2', 'tf_efficientnetv2_b3', 'tf_efficientnetv2_l', 'tf_efficientnetv2_m', 'tf_efficientnetv2_s', 'tf_efficientnetv2_xl', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100', 'tiny_vit_5m_224', 'tiny_vit_11m_224', 'tiny_vit_21m_224', 'tiny_vit_21m_384', 'tiny_vit_21m_512', 'tinynet_a', 'tinynet_b', 'tinynet_c', 'tinynet_d', 'tinynet_e', 'tnt_b_patch16_224', 'tnt_s_legacy_patch16_224', 'tnt_s_patch16_224', 'tresnet_l', 'tresnet_m', 'tresnet_v2_l', 'tresnet_xl', 'twins_pcpvt_base', 'twins_pcpvt_large', 'twins_pcpvt_small', 'twins_svt_base', 'twins_svt_large', 'twins_svt_small', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'visformer_small', 'visformer_tiny', 'vit_7b_patch16_dinov3', 'vit_base_mci_224', 'vit_base_patch8_224', 'vit_base_patch14_dinov2', 'vit_base_patch14_reg4_dinov2', 'vit_base_patch16_18x2_224', 'vit_base_patch16_224', 'vit_base_patch16_224_miil', 'vit_base_patch16_384', 'vit_base_patch16_clip_224', 'vit_base_patch16_clip_384', 'vit_base_patch16_clip_quickgelu_224', 'vit_base_patch16_dinov3', 'vit_base_patch16_dinov3_qkvb', 'vit_base_patch16_gap_224', 'vit_base_patch16_plus_240', 'vit_base_patch16_plus_clip_240', 'vit_base_patch16_reg4_gap_256', 'vit_base_patch16_rope_224', 'vit_base_patch16_rope_ape_224', 'vit_base_patch16_rope_mixed_224', 'vit_base_patch16_rope_mixed_ape_224', 'vit_base_patch16_rope_reg1_gap_256', 'vit_base_patch16_rpn_224', 'vit_base_patch16_siglip_224', 'vit_base_patch16_siglip_256', 'vit_base_patch16_siglip_384', 'vit_base_patch16_siglip_512', 'vit_base_patch16_siglip_gap_224', 'vit_base_patch16_siglip_gap_256', 'vit_base_patch16_siglip_gap_384', 'vit_base_patch16_siglip_gap_512', 'vit_base_patch16_xp_224', 'vit_base_patch32_224', 'vit_base_patch32_384', 'vit_base_patch32_clip_224', 'vit_base_patch32_clip_256', 'vit_base_patch32_clip_384', 'vit_base_patch32_clip_448', 'vit_base_patch32_clip_quickgelu_224', 'vit_base_patch32_plus_256', 'vit_base_patch32_siglip_256', 'vit_base_patch32_siglip_gap_256', 'vit_base_r26_s32_224', 'vit_base_r50_s16_224', 'vit_base_r50_s16_384', 'vit_base_resnet26d_224', 'vit_base_resnet50d_224', 'vit_betwixt_patch16_gap_256', 'vit_betwixt_patch16_reg1_gap_256', 'vit_betwixt_patch16_reg4_gap_256', 'vit_betwixt_patch16_reg4_gap_384', 'vit_betwixt_patch16_rope_reg4_gap_256', 'vit_betwixt_patch32_clip_224', 'vit_giant_patch14_224', 'vit_giant_patch14_clip_224', 'vit_giant_patch14_dinov2', 'vit_giant_patch14_reg4_dinov2', 'vit_giant_patch16_gap_224', 'vit_giantopt_patch16_siglip_256', 'vit_giantopt_patch16_siglip_384', 'vit_giantopt_patch16_siglip_gap_256', 'vit_giantopt_patch16_siglip_gap_384', 'vit_gigantic_patch14_224', 'vit_gigantic_patch14_clip_224', 'vit_gigantic_patch14_clip_378', 'vit_gigantic_patch14_clip_quickgelu_224', 'vit_huge_patch14_224', 'vit_huge_patch14_clip_224', 'vit_huge_patch14_clip_336', 'vit_huge_patch14_clip_378', 'vit_huge_patch14_clip_quickgelu_224', 'vit_huge_patch14_clip_quickgelu_378', 'vit_huge_patch14_gap_224', 'vit_huge_patch14_xp_224', 'vit_huge_patch16_gap_448', 'vit_huge_plus_patch16_dinov3', 'vit_huge_plus_patch16_dinov3_qkvb', 'vit_intern300m_patch14_448', 'vit_large_patch14_224', 'vit_large_patch14_clip_224', 'vit_large_patch14_clip_336', 'vit_large_patch14_clip_quickgelu_224', 'vit_large_patch14_clip_quickgelu_336', 'vit_large_patch14_dinov2', 'vit_large_patch14_reg4_dinov2', 'vit_large_patch14_xp_224', 'vit_large_patch16_224', 'vit_large_patch16_384', 'vit_large_patch16_dinov3', 'vit_large_patch16_dinov3_qkvb', 'vit_large_patch16_rope_224', 'vit_large_patch16_rope_ape_224', 'vit_large_patch16_rope_mixed_224', 'vit_large_patch16_rope_mixed_ape_224', 'vit_large_patch16_siglip_256', 'vit_large_patch16_siglip_384', 'vit_large_patch16_siglip_512', 'vit_large_patch16_siglip_gap_256', 'vit_large_patch16_siglip_gap_384', 'vit_large_patch16_siglip_gap_512', 'vit_large_patch32_224', 'vit_large_patch32_384', 'vit_large_r50_s32_224', 'vit_large_r50_s32_384', 'vit_little_patch16_reg1_gap_256', 'vit_little_patch16_reg4_gap_256', 'vit_medium_patch16_clip_224', 'vit_medium_patch16_gap_240', 'vit_medium_patch16_gap_256', 'vit_medium_patch16_gap_384', 'vit_medium_patch16_reg1_gap_256', 'vit_medium_patch16_reg4_gap_256', 'vit_medium_patch16_rope_reg1_gap_256', 'vit_medium_patch32_clip_224', 'vit_mediumd_patch16_reg4_gap_256', 'vit_mediumd_patch16_reg4_gap_384', 'vit_mediumd_patch16_rope_reg1_gap_256', 'vit_pe_core_base_patch16_224', 'vit_pe_core_gigantic_patch14_448', 'vit_pe_core_large_patch14_336', 'vit_pe_core_small_patch16_384', 'vit_pe_core_tiny_patch16_384', 'vit_pe_lang_gigantic_patch14_448', 'vit_pe_lang_large_patch14_448', 'vit_pe_spatial_base_patch16_512', 'vit_pe_spatial_gigantic_patch14_448', 'vit_pe_spatial_large_patch14_448', 'vit_pe_spatial_small_patch16_512', 'vit_pe_spatial_tiny_patch16_512', 'vit_pwee_patch16_reg1_gap_256', 'vit_relpos_base_patch16_224', 'vit_relpos_base_patch16_cls_224', 'vit_relpos_base_patch16_clsgap_224', 'vit_relpos_base_patch16_plus_240', 'vit_relpos_base_patch16_rpn_224', 'vit_relpos_base_patch32_plus_rpn_256', 'vit_relpos_medium_patch16_224', 'vit_relpos_medium_patch16_cls_224', 'vit_relpos_medium_patch16_rpn_224', 'vit_relpos_small_patch16_224', 'vit_relpos_small_patch16_rpn_224', 'vit_small_patch8_224', 'vit_small_patch14_dinov2', 'vit_small_patch14_reg4_dinov2', 'vit_small_patch16_18x2_224', 'vit_small_patch16_36x1_224', 'vit_small_patch16_224', 'vit_small_patch16_384', 'vit_small_patch16_dinov3', 'vit_small_patch16_dinov3_qkvb', 'vit_small_patch16_rope_224', 'vit_small_patch16_rope_ape_224', 'vit_small_patch16_rope_mixed_224', 'vit_small_patch16_rope_mixed_ape_224', 'vit_small_patch32_224', 'vit_small_patch32_384', 'vit_small_plus_patch16_dinov3', 'vit_small_plus_patch16_dinov3_qkvb', 'vit_small_r26_s32_224', 'vit_small_r26_s32_384', 'vit_small_resnet26d_224', 'vit_small_resnet50d_s16_224', 'vit_so150m2_patch16_reg1_gap_256', 'vit_so150m2_patch16_reg1_gap_384', 'vit_so150m2_patch16_reg1_gap_448', 'vit_so150m_patch16_reg4_gap_256', 'vit_so150m_patch16_reg4_gap_384', 'vit_so150m_patch16_reg4_map_256', 'vit_so400m_patch14_siglip_224', 'vit_so400m_patch14_siglip_378', 'vit_so400m_patch14_siglip_384', 'vit_so400m_patch14_siglip_gap_224', 'vit_so400m_patch14_siglip_gap_378', 'vit_so400m_patch14_siglip_gap_384', 'vit_so400m_patch14_siglip_gap_448', 'vit_so400m_patch14_siglip_gap_896', 'vit_so400m_patch16_siglip_256', 'vit_so400m_patch16_siglip_384', 'vit_so400m_patch16_siglip_512', 'vit_so400m_patch16_siglip_gap_256', 'vit_so400m_patch16_siglip_gap_384', 'vit_so400m_patch16_siglip_gap_512', 'vit_srelpos_medium_patch16_224', 'vit_srelpos_small_patch16_224', 'vit_tiny_patch16_224', 'vit_tiny_patch16_384', 'vit_tiny_r_s16_p8_224', 'vit_tiny_r_s16_p8_384', 'vit_wee_patch16_reg1_gap_256', 'vit_xsmall_patch16_clip_224', 'vitamin_base_224', 'vitamin_large2_224', 'vitamin_large2_256', 'vitamin_large2_336', 'vitamin_large2_384', 'vitamin_large_224', 'vitamin_large_256', 'vitamin_large_336', 'vitamin_large_384', 'vitamin_small_224', 'vitamin_xlarge_256', 'vitamin_xlarge_336', 'vitamin_xlarge_384', 'volo_d1_224', 'volo_d1_384', 'volo_d2_224', 'volo_d2_384', 'volo_d3_224', 'volo_d3_448', 'volo_d4_224', 'volo_d4_448', 'volo_d5_224', 'volo_d5_448', 'volo_d5_512', 'vovnet39a', 'vovnet57a', 'wide_resnet50_2', 'wide_resnet101_2', 'xception41', 'xception41p', 'xception65', 'xception65p', 'xception71', 'xcit_large_24_p8_224', 'xcit_large_24_p8_384', 'xcit_large_24_p16_224', 'xcit_large_24_p16_384', 'xcit_medium_24_p8_224', 'xcit_medium_24_p8_384', 'xcit_medium_24_p16_224', 'xcit_medium_24_p16_384', 'xcit_nano_12_p8_224', 'xcit_nano_12_p8_384', 'xcit_nano_12_p16_224', 'xcit_nano_12_p16_384', 'xcit_small_12_p8_224', 'xcit_small_12_p8_384', 'xcit_small_12_p16_224', 'xcit_small_12_p16_384', 'xcit_small_24_p8_224', 'xcit_small_24_p8_384', 'xcit_small_24_p16_224', 'xcit_small_24_p16_384', 'xcit_tiny_12_p8_224', 'xcit_tiny_12_p8_384', 'xcit_tiny_12_p16_224', 'xcit_tiny_12_p16_384', 'xcit_tiny_24_p8_224', 'xcit_tiny_24_p8_384', 'xcit_tiny_24_p16_224', 'xcit_tiny_24_p16_384']\n",
      "Eva(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (rope): RotaryEmbeddingDinoV3()\n",
      "  (norm_pre): Identity()\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x EvaBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): EvaAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc_norm): Identity()\n",
      "  (head_drop): Dropout(p=0.0, inplace=False)\n",
      "  (head): Identity()\n",
      ")\n",
      "torch.Size([1, 384])\n",
      "model loaded\n",
      "21586944\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def load_model():\n",
    "    # list all timm supported models\n",
    "    model_list = timm.list_models()\n",
    "    print(model_list)\n",
    "    \n",
    "    # timm.create_model is used to load pretrained vision model, pretrained to determine if load weights\n",
    "    model = timm.create_model('timm/vit_small_patch16_dinov3.lvd1689m', pretrained=True, num_classes=0)\n",
    "    print(model)\n",
    "\n",
    "    input_temp = torch.randn((1, 3, 256, 256))\n",
    "    print(model(input_temp).shape) # get the shape of the output\n",
    "    \n",
    "    # timm.create_model is used to\n",
    "    model.eval()  # set the model in evaluation mode\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    print(\"model loaded\")\n",
    "    print(sum(param.numel() for param in model.parameters()))\n",
    "    return model\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a41223-e14e-443f-8190-fdad3c45ccda",
   "metadata": {},
   "source": [
    "# Define new target model\n",
    "* Define a simple 10-classes linear classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b6edff-539c-4b21-8cb8-9f2c31798790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimensio is 384\n",
      "Defined classification model\n",
      "10\n",
      "384\n",
      "CustomDINOv3(\n",
      "  (backbone): Eva(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (rope): RotaryEmbeddingDinoV3()\n",
      "    (norm_pre): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x EvaBlock(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): EvaAttention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc_norm): Identity()\n",
      "    (head_drop): Dropout(p=0.0, inplace=False)\n",
      "    (head): Identity()\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def def_model(model):\n",
    "    # Extract dinov3 features\n",
    "    feature_dim = model.num_features\n",
    "    print(f\"feature dimensio is {feature_dim}\")\n",
    "    # Set 10 classes\n",
    "    num_classes = 10\n",
    "    # Create a simple MLP\n",
    "    classifier = nn.Sequential(\n",
    "        nn.Linear(feature_dim, 256),\n",
    "        # nn.ReLU(inplace=True), # inplace replace the input with output\n",
    "        nn.ReLU(), # inplace replace the input with output\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    # Connect the backbone with the classifier head\n",
    "    class CustomDINOv3(nn.Module):\n",
    "        def __init__(self, backbone, head):\n",
    "            super().__init__()\n",
    "            self.backbone = backbone\n",
    "            self.head = head\n",
    "\n",
    "        def forward(self, x):\n",
    "            features = self.backbone(x)\n",
    "            output = self.head(features)\n",
    "            return output\n",
    "\n",
    "    custom_model = CustomDINOv3(model, classifier)\n",
    "    print(\"Defined classification model\")\n",
    "    return custom_model, num_classes, feature_dim\n",
    "\n",
    "custom_model, num_classes, feature_dim = def_model(model)\n",
    "print(num_classes)\n",
    "print(feature_dim)\n",
    "print(custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c30c5f-46a3-4055-8b7e-6ad24dbf28c1",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "* CIFAR-10 dataset: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "* This data set has 60000 32*32 images in 10 classes, 6000 per class\n",
    "* Use datasets & dataloader lib: https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08f4d932-cc3c-4024-89cd-c8f4a5717991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': (3, 256, 256), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 1.0, 'crop_mode': 'center'}\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "dataset loaded\n",
      "torch.Size([3, 256, 256])\n",
      "tensor([[[-1.5014, -1.5014, -1.5014,  ..., -1.6042, -1.6042, -1.6042],\n",
      "         [-1.5014, -1.5014, -1.5014,  ..., -1.6042, -1.6042, -1.6042],\n",
      "         [-1.5014, -1.5014, -1.5014,  ..., -1.6042, -1.6042, -1.6042],\n",
      "         ...,\n",
      "         [-0.7993, -0.7993, -0.7993,  ..., -1.2959, -1.3130, -1.3130],\n",
      "         [-0.7993, -0.7993, -0.7993,  ..., -1.2959, -1.3130, -1.3130],\n",
      "         [-0.7993, -0.7993, -0.7993,  ..., -1.2959, -1.3130, -1.3130]],\n",
      "\n",
      "        [[-1.5105, -1.5105, -1.5105,  ..., -1.4405, -1.4405, -1.4405],\n",
      "         [-1.5105, -1.5105, -1.5105,  ..., -1.4405, -1.4405, -1.4405],\n",
      "         [-1.5105, -1.5105, -1.5105,  ..., -1.4405, -1.4405, -1.4405],\n",
      "         ...,\n",
      "         [-0.7052, -0.7052, -0.7052,  ..., -1.2129, -1.2129, -1.2129],\n",
      "         [-0.7052, -0.7052, -0.7052,  ..., -1.2129, -1.2129, -1.2129],\n",
      "         [-0.7052, -0.7052, -0.7052,  ..., -1.2129, -1.2129, -1.2129]],\n",
      "\n",
      "        [[-1.3164, -1.3164, -1.3164,  ..., -1.4210, -1.4210, -1.4210],\n",
      "         [-1.3164, -1.3164, -1.3164,  ..., -1.4210, -1.4210, -1.4210],\n",
      "         [-1.3164, -1.3164, -1.3164,  ..., -1.4210, -1.4210, -1.4210],\n",
      "         ...,\n",
      "         [-0.5670, -0.5670, -0.5670,  ..., -1.0201, -1.0201, -1.0201],\n",
      "         [-0.5670, -0.5670, -0.5670,  ..., -1.0201, -1.0201, -1.0201],\n",
      "         [-0.5670, -0.5670, -0.5670,  ..., -1.0201, -1.0201, -1.0201]]])\n",
      "tensor(6)\n",
      "torch.Size([3, 256, 256])\n",
      "tensor([[[ 0.8447,  0.8618,  0.8618,  ...,  0.6906,  0.6906,  0.6906],\n",
      "         [ 0.8447,  0.8618,  0.8618,  ...,  0.6906,  0.6906,  0.6906],\n",
      "         [ 0.8447,  0.8618,  0.8618,  ...,  0.6906,  0.6906,  0.6906],\n",
      "         ...,\n",
      "         [ 0.1768,  0.1768,  0.1768,  ...,  1.6838,  1.6838,  1.6838],\n",
      "         [ 0.1768,  0.1768,  0.1768,  ...,  1.6838,  1.6838,  1.6838],\n",
      "         [ 0.1768,  0.1768,  0.1768,  ...,  1.7009,  1.6838,  1.6838]],\n",
      "\n",
      "        [[ 0.3452,  0.3452,  0.3452,  ...,  0.1527,  0.1527,  0.1352],\n",
      "         [ 0.3452,  0.3452,  0.3452,  ...,  0.1527,  0.1527,  0.1352],\n",
      "         [ 0.3452,  0.3452,  0.3452,  ...,  0.1527,  0.1527,  0.1352],\n",
      "         ...,\n",
      "         [-0.2150, -0.2150, -0.2150,  ...,  1.3256,  1.2906,  1.2906],\n",
      "         [-0.2150, -0.2150, -0.2150,  ...,  1.3431,  1.3256,  1.3256],\n",
      "         [-0.2150, -0.2150, -0.2150,  ...,  1.3431,  1.3256,  1.3256]],\n",
      "\n",
      "        [[ 0.2522,  0.2522,  0.2522,  ...,  0.0431,  0.0431,  0.0431],\n",
      "         [ 0.2522,  0.2522,  0.2522,  ...,  0.0431,  0.0431,  0.0431],\n",
      "         [ 0.2696,  0.2696,  0.2696,  ...,  0.0431,  0.0431,  0.0431],\n",
      "         ...,\n",
      "         [-0.2707, -0.2707, -0.2707,  ...,  1.0888,  1.0888,  1.0888],\n",
      "         [-0.2707, -0.2707, -0.2707,  ...,  1.1062,  1.1062,  1.1062],\n",
      "         [-0.2707, -0.2707, -0.2707,  ...,  1.1062,  1.1062,  1.1062]]])\n",
      "tensor(5)\n",
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "    \n",
    "def load_dataset(model):\n",
    "    # obtain the data config corresponding to the model\n",
    "    # timm get the data preprocess config for vision model, which can be used to get transforms\n",
    "    data_config = timm.data.resolve_model_data_config(model) \n",
    "    print(data_config)\n",
    "    transforms = timm.data.create_transform(\n",
    "        **data_config,\n",
    "        is_training=True\n",
    "    )\n",
    "    # Download CIFAR-10 dataset\n",
    "    # CIFAR-10 dataset: 60000 32x32 colour images in 10 classes, with 6000 images per class\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root = './data',\n",
    "        train = True,\n",
    "        download = True,\n",
    "        transform = transforms\n",
    "    )\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root = './data',\n",
    "        train = False,\n",
    "        download = True,\n",
    "        transform = transforms\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = 32,\n",
    "        shuffle = True,\n",
    "        num_workers = 12\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size = 32,\n",
    "        shuffle = True,\n",
    "        num_workers = 12\n",
    "    )\n",
    "    print(\"dataset loaded\")\n",
    "    return train_loader, test_loader, data_config\n",
    "\n",
    "train_loader, test_loader, dataconfig = load_dataset(model)\n",
    "count = 0\n",
    "for images, labels in train_loader:\n",
    "    to_pil = ToPILImage()\n",
    "    image_tensor = images[0, :, :, :]\n",
    "    print(image_tensor.shape)\n",
    "    image = to_pil(image_tensor)\n",
    "    print(image_tensor)\n",
    "    image.show()\n",
    "    print(labels[0])\n",
    "    count+=1\n",
    "    if count > 1: break\n",
    "\n",
    "totensor_transform = transforms.ToTensor()\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root = './data',\n",
    "    train = False,\n",
    "    download = True,\n",
    ")\n",
    "image_pil = test_dataset[1][0]\n",
    "image_pil.show()\n",
    "image_tensor = totensor_transform(image_pil)\n",
    "print(image_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b99cf-442f-4057-aec0-f216dbeebb6e",
   "metadata": {},
   "source": [
    "# Train\n",
    "* Train 10 epoch, get loss close or below 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3b0b28f-cdd8-47d2-a306-4d29f29f7a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5261\n",
      "Epoch [2/10], Loss: 0.4342\n",
      "Epoch [3/10], Loss: 0.4184\n",
      "Epoch [4/10], Loss: 0.4075\n",
      "Epoch [5/10], Loss: 0.3980\n",
      "Epoch [6/10], Loss: 0.3928\n",
      "Epoch [7/10], Loss: 0.3952\n",
      "Epoch [8/10], Loss: 0.3858\n",
      "Epoch [9/10], Loss: 0.3806\n",
      "Epoch [10/10], Loss: 0.3766\n",
      "Train completed\n"
     ]
    }
   ],
   "source": [
    "def train_model(custom_model, train_loader):\n",
    "    custom_model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Adam to optimze the classification hear\n",
    "    optimizer = optim.Adam(custom_model.head.parameters(), lr=0.001)\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        custom_model.train()  # set the model to train mode\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = custom_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    print(\"Train completed\")\n",
    "\n",
    "train_model(custom_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d2063-eec2-439e-aa8c-9b7d5b528f98",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0dd747d-73c5-4f13-89d9-bd5d94f30deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "def save_model(custom_model, num_classes, feature_dim, data_config):\n",
    "    torch.save({\n",
    "        'classifier_state_dict': custom_model.head.state_dict(),\n",
    "        'num_classes': num_classes,\n",
    "        'feature_dim': feature_dim,\n",
    "        'training_config': {\n",
    "            'model_name': 'facebook/dinov3-base-pretrain-lvd1689m',\n",
    "            'input_size': data_config['input_size']\n",
    "        }\n",
    "    }, 'dino_classifier_head.pth')\n",
    "    print('model saved')\n",
    "\n",
    "save_model(custom_model, num_classes, feature_dim, dataconfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82d966-929a-45c0-a83b-bed4665e4187",
   "metadata": {},
   "source": [
    "# Evaluated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b22613f0-18cf-47cd-b860-cc46d529973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 87.15%\n"
     ]
    }
   ],
   "source": [
    "def eval_model(custom_model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    custom_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = custom_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"accuracy is: {100* correct / total:.2f}%\")\n",
    "\n",
    "eval_model(custom_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683c716e-f433-4862-a30a-8073cb2d3a41",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c389ec9-13db-4f9d-9046-45a2b1866c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(data_config, file_path):\n",
    "    transforms = timm.data.create_transform(\n",
    "        **data_config,\n",
    "        is_training=False\n",
    "    )\n",
    "    if isinstance(file_path, str):\n",
    "        image = Image.open(file_path).convert('RGB')\n",
    "    else:\n",
    "        image = file_path.convert('RGB')\n",
    "    input_tensor = transforms(image).unsqueeze(0).to(device)\n",
    "    return input_tensor\n",
    "\n",
    "def classifier(model, input_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prob = torch.softmax(output, dim=1)\n",
    "        confidence, predicted = torch.max(prob, 1)\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                  'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    print(f\"Predicted: {class_names[predicted.item()]}\")\n",
    "    return class_names[predicted.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f718ebdf-c6da-49c3-8427-0e55d7cc3b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Predicted: cat\n",
      "Predicted: dog\n",
      "Predicted: airplane\n"
     ]
    }
   ],
   "source": [
    "image_path_1 = \"/home/yang/MyRepos/object_detection/images/cat2.jpg\"\n",
    "image_path_2 = \"/home/yang/MyRepos/object_detection/images/dog1.jpg\"\n",
    "valid_dataset = datasets.CIFAR10(\n",
    "    root = './data',\n",
    "    train = False,\n",
    "    download = True,\n",
    ")\n",
    "\n",
    "image = Image.open(image_path_1).convert('RGB')\n",
    "image.show()\n",
    "input_tensor = process_image(dataconfig, image_path_1)\n",
    "class_name = classifier(custom_model, input_tensor)\n",
    "\n",
    "image = Image.open(image_path_2).convert('RGB')\n",
    "image.show()\n",
    "input_tensor = process_image(dataconfig, image_path_2)\n",
    "class_name = classifier(custom_model, input_tensor)\n",
    "\n",
    "image = valid_dataset[10][0]\n",
    "image.show()\n",
    "input_tensor = process_image(dataconfig, image)\n",
    "class_name = classifier(custom_model, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "797ba78f-859b-4e34-93e0-4969d44c8770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: cat\n"
     ]
    }
   ],
   "source": [
    "image = valid_dataset[53][0]\n",
    "image_resized = image.resize((100, 100))\n",
    "image_resized.show()\n",
    "input_tensor = process_image(dataconfig, image)\n",
    "class_name = classifier(custom_model, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb6e56a9-2215-45e6-91d0-79b8dc07eb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x76edc473e480>\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = datasets.CIFAR10(\n",
    "    root = './data',\n",
    "    train = False,\n",
    "    download = True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    num_workers = 12\n",
    ")\n",
    "\n",
    "print(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543512c1-8e8f-45e4-8ff6-ba9bc83f4a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dinov3)",
   "language": "python",
   "name": "dinov3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
